
# Projet de tarification auto en python avec comparaison ML et impl√©mentation de Fairness

Ce projet propose une approche moderne de la mod√©lisation de la prime pure en utilisant le dataset freMTPL2, l'objectif de ce projet est de comparer les outils classiques en actuariat (GLM Poisson/ Gamma) aux outils de machine learning actuels et de regarder les enjeux √©thiques de ces mod√®les performants.

## Explication

La pipeline de mon projet se d√©compose en une premi√®re phase de pr√©paration des donn√©es √† travers l'EDA de la Fr√©quence puis de la S√©v√©rit√©, une seconde phase de comparaison de mod√®les et d'entra√Ænement de mod√®les, le choix du mod√®le fr√©quence final et du mod√®le s√©v√©rit√© finazl se basera sur diff√©rentes m√©triques telles que le Mean Square Error et la d√©viance Poisson pour la mod√©lisation de la fr√©quence et le MAE et la d√©viance Gamma pour la mod√©lisation de la s√©v√©rit√© , et pour finir une derni√®re phase de v√©rification √©thique sur les mod√®les gagnants du comparatif.

Le projet est structur√© de mani√®re s√©quentielle, de l'acquisition des donn√©es √† l'audit √©thique final :

![Structure de la pipeline](https://github.com/user-attachments/assets/d1d4cdd8-ec5a-4fed-b77d-c527df19efa0)

Tout d'abord, voici ce que repr√©sente nos donn√©es:

![Structure de la pipeline](https://github.com/user-attachments/assets/a2c009e1-d1f3-41f0-92b8-e689a30ed450)

Pour commencer, j'ai supprimer toutes les valeurs qui sont aberrantes, c'est des donn√©es qui sont tr√®s certainement des erreurs de saisies et doivent √™tre supprim√©s, je ne les ai pas normalis√© ou windsoris√© car dans ce dataset, tr√®s peyu de valeurs sont aberrantes, les supprimer ne nuit donc pas √† nos mod√®les.

Par la suite, j'ai split mes donn√©es en train/test, je les ai splitt√© aussi t√¥t dans le projet pour √©viter au maximum les fuites de donn√©es, c'est pour cette raison que mon analyse exploratoire de donn√©es se portent uniquement sur le dataframe train,  

Pour estimer la prime pure, on d√©coupe le projet en 2 parties, une premi√®re qui a pour objectif d'estimer la fr√©quence qu'un client rencontre un accident et un second pour calculer le montant de la r√©clamation si il y en a une, 

Les donn√©es du dataset freMTPL2 pr√©sentent de nombreux challenges, premi√®rement, il est tr√®s difficile d'estimer sur ce dataset `ClaimAmount` car on dispose de tr√®s peu d'informations susceptibles d'obtenir une bonne estimation de cette variable,














































![Structure de la pipeline](https://github.com/user-attachments/assets/a0dce2db-2c1a-4f90-a57a-d9e782c22417)

Gemini:

üöó Projet de Tarification Assurance AutoCe projet a pour objectif de mod√©liser la Prime Pure ($Prime\ Pure = Fr√©quence \times S√©v√©rit√©$) en utilisant les jeux de donn√©es de r√©f√©rence en actuariat : freMTPL2freq (fr√©quence des sinistres) et freMTPL2sev (co√ªt moyen des sinistres).


üéØ Objectifs

Le projet s'articule autour de trois axes principaux :

Performance : Comparer la pr√©cision des mod√®les d'ensemble (XGBoost, LightGBM) par rapport aux mod√®les lin√©aires g√©n√©ralis√©s (GLM).
Interpr√©tabilit√© : Analyser le compromis entre la puissance pr√©dictive des mod√®les "bo√Æte noire" et la transparence n√©cessaire en assurance.
√âquit√© : Auditer le mod√®le final pour d√©tecter d'√©ventuels biais discriminatoires envers certaines cat√©gories d'assur√©s (audit via Fairlearn).

üõ†Ô∏è M√©thodologie

L'approche technique est divis√©e en trois phases :Data Engineering : Nettoyage, traitement des valeurs aberrantes (ex: expositions n√©gatives, montants extr√™mes) et fusion des donn√©es fr√©quence/s√©v√©rit√©.Mod√©lisation :Baseline (GLM) : Utilisation de lois de Poisson (Fr√©quence) et Gamma (Co√ªt moyen).Machine Learning : Impl√©mentation de Random Forest, XGBoost et LightGBM.√âvaluation : Mesure de la performance via le RMSE et la d√©viance de Poisson.



üìä Structure du NotebookChargement des donn√©es : Importation des biblioth√®ques (scikit-learn, xgboost, lightgbm, fairlearn, shap) et des datasets.Pr√©paration & Feature Engineering : Cr√©ation de variables synth√©tiques et gestion des donn√©es brutes.Exploration de Donn√©es (EDA) : Analyse statistique univari√©e et d√©tection des valeurs atypiques.Entra√Ænement des Mod√®les : (D√©tail de la construction des pipelines de transformation et des mod√®les de r√©gression).Audit d'√âquit√© : Analyse de l'impact disparate selon l'√¢ge du conducteur ou d'autres variables sensibles.üì¶ Biblioth√®ques Utilis√©espandas, numpy : Manipulation des donn√©es.matplotlib, seaborn : Visualisation.statsmodels, scikit-learn : Mod√©lisation statistique et ML.xgboost, lightgbm : Mod√®les de gradient boosting.shap : Interpr√©tabilit√© locale et globale.fairlearn : Analyse de l'√©quit√© algorithmique.



üöÄ R√©sultats Cl√©s(Note : √Ä compl√©ter selon vos conclusions finales dans le notebook)Les mod√®les de Boosting surpassent g√©n√©ralement les GLM en termes de d√©viance.L'analyse SHAP r√©v√®le que les variables comme le BonusMalus et la Density sont des pr√©dicteurs majeurs.L'audit d'√©quit√© permet d'ajuster les tarifs pour √©viter une sur-p√©nalisation injustifi√©e de certains segments
